# PersonaForge - Telegram Bot with Human-like AI

## Цель проекта

Создать Telegram-бота на Rust, который ведет диалог "как реальный человек" в личных чатах и в группах/супергруппах, с настраиваемой персоной и памятью на базе RAG (Retrieval Augmented Generation), используя локальную Ollama, запущенную на хост-машине.

## Реализованный функционал (на текущий момент)

На данный момент реализован базовый каркас бота с ключевыми функциями для демонстрации основной концепции:

-   **Работа в личных чатах:** Бот отвечает на сообщения в личных чатах.
-   **Базовая генерация ответов:** Используется локальная модель Ollama для генерации ответов.
-   **Контекст диалога (short-term memory):** Бот поддерживает контекст последних N сообщений чата (в памяти).
-   **RAG-память:**
    -   Сохранение фактов/фрагментов диалога и/или заметок в локальной базе данных SQLite.
    -   Поиск релевантных фрагментов по embedding similarity (также через Ollama) и добавление их в контекст ответа.
-   **Персона:** Бот использует настраиваемую "манеру речи" через system prompt, который может быть загружен из базы данных.
-   **Docker-first:** Бот запускается в Docker-контейнере и подключается к Ollama, работающей на хосте.
-   **Надёжность:** Встроены базовые механизмы таймаутов на запросы к Ollama и примитивный rate limiting (cooldown) на основе настроек чата.
-   **Безопасность:** Запросы к Ollama обрабатываются с базовой логикой ошибок.
-   **Конфиденциальность:** Хранение данных настроено для локальной SQLite, что обеспечивает контроль над данными.

## Технологии

-   **Язык:** Rust
-   **Telegram SDK:** `teloxide`
-   **LLM:** Ollama (локально на хосте)
-   **База данных:** SQLite (через `sqlx`)
-   **Сериализация эмбеддингов:** `bincode`
-   **Асинхронность:** `tokio`
-   **Конфигурация:** `dotenv`, `envy`
-   **Логирование:** `pretty_env_logger`
-   **Контейнеризация:** Docker, `docker-compose`

## Настройка и запуск

Для запуска бота вам потребуется установленный Docker, Ollama и аккаунт в Telegram для создания бота.

### 1. Клонирование репозитория

```bash
git clone https://github.com/your-username/PersonaForge.git
cd PersonaForge
```

### 2. Создание Telegram-бота

1.  Откройте Telegram и найдите [@BotFather](https://t.me/BotFather).
2.  Отправьте ему команду `/newbot`.
3.  Следуйте инструкциям BotFather, чтобы создать нового бота и получить его токен. Сохраните этот токен.
4.  Получите ваш Telegram User ID, используя бота, например, [@userinfobot](https://t.me/userinfobot). Сохраните этот ID.

### 3. Настройка переменных окружения

Создайте файл `.env` в корневой директории проекта, скопировав `.env.example`:

```bash
cp .env.example .env
```

Затем отредактируйте файл `.env`, заполнив значения:

```ini
TELOXIDE_TOKEN=ВАШ_ТОКЕН_БОТА
DATABASE_URL=sqlite:persona_forge.db
OWNER_ID=ВАШ_TELEGRAM_USER_ID
OLLAMA_URL=http://host.docker.internal:11434 # URL для Ollama, запущенной на хосте
OLLAMA_CHAT_MODEL=gemini-3-flash-preview:cloud # Модель чата по умолчанию
OLLAMA_EMBEDDING_MODEL=nomic-embed-text # Модель для эмбеддингов по умолчанию
```

-   `TELOXIDE_TOKEN`: Токен, полученный от BotFather.
-   `DATABASE_URL`: Путь к файлу SQLite базы данных. `sqlite:persona_forge.db` по умолчанию создаст файл `persona_forge.db` в корне проекта.
-   `OWNER_ID`: Ваш Telegram User ID. Это необходимо для будущей панели владельца.
-   `OLLAMA_URL`: URL, по которому бот будет подключаться к Ollama. `http://host.docker.internal:11434` работает для Docker Desktop на Windows и macOS. Для Linux, если Ollama запущена на порту 11434, это может быть `http://172.17.0.1:11434` или IP вашей машины в Docker-сети.

### 4. Подготовка Ollama на хост-машине

1.  **Установите Ollama:** Следуйте инструкциям на [ollama.com](https://ollama.com/download) для вашей операционной системы.
2.  **Загрузите модели:** Откройте терминал и выполните следующие команды для загрузки моделей, которые будет использовать бот:
    ```bash
    ollama pull gemini-3-flash-preview:cloud
    ollama pull nomic-embed-text
    ```
    Это может занять некоторое время в зависимости от вашего интернет-соединения.
3.  **Запустите Ollama:** Убедитесь, что Ollama запущена и доступна на порту 11434. Обычно она запускается как фоновый сервис после установки.

### 5. Запуск бота

Выполните следующую команду в корневой директории проекта:

```bash
docker-compose up --build
```

-   `--build`: Обязателен при первом запуске или после изменений в коде Rust, чтобы пересобрать образ бота.

После успешного запуска бот будет готов к работе.

### 6. Взаимодействие с ботом

Просто отправляйте сообщения вашему боту в личных сообщениях. Он будет использовать Ollama для генерации ответов, основываясь на текущем контексте и своей RAG-памяти.

## Дальнейшие планы и TODO

Следующие шаги для развития проекта, частично основанные на изначальном ТЗ:

-   **Полная реализация Owner-панели:**
    -   ✅ CRUD для персон (создание, редактирование, активация).
    -   ✅ Выбор модели Ollama и параметров генерации (temperature, max tokens).
    -   ✅ Включение/выключение RAG и настройка глубины памяти.
    -   ✅ Просмотр статуса Ollama и БД.
-   **Полная реализация Админки чата:**
    -   ✅ Включение/выключение автоответов.
    -   ✅ Режим ответа: "только по упоминанию/команде" vs "на все сообщения".
    -   ✅ Настройки частоты ответов/антиспам (cooldown).
    -   ✅ Контекст (N последних сообщений в prompt).
-   **Улучшение "человечного" поведения:** Добавление правил, чтобы избежать повторений, раскрытия того, что это бот, аккуратное обращение с персональными данными.
-   **Улучшенное логирование и метрики:** Более детальное логирование, трассировка запросов, сбор метрик (время ответа, ошибки Ollama, нагрузка).
-   **Миграции БД:** Автоматическое применение миграций.
-   **Расширение RAG:** Развитие механизма "memory_chunks" для более гранулярного хранения и извлечения информации.
-   **Очереди/лимиты на генерацию:** Дополнительные механизмы для предотвращения перегрузки Ollama.
-   **Обработка ошибок:** БолееRobustная обработка ошибок для запросов к Ollama.

## Команды бота

Владелец бота может использовать следующие команды:

### Управление персонами:
- `/create_persona название|описание` - Создать новую персону
- `/list_personas` - Показать все персоны
- `/activate_persona ID` - Активировать персону по ID
- `/update_persona ID|название|описание` - Обновить персону
- `/delete_persona ID` - Удалить персону по ID

### Настройки модели:
- `/set_model название` - Установить модель Ollama
- `/set_temperature значение` - Установить температуру (0.0-2.0)
- `/set_max_tokens значение` - Установить максимальное количество токенов

### Настройки RAG:
- `/enable_rag` - Включить RAG (поиск по памяти)
- `/disable_rag` - Отключить RAG (поиск по памяти)
- `/set_memory_depth значение` - Установить глубину памяти (1-50 сообщений)

### Настройки чата:
- `/enable_auto_reply` - Включить автоответы
- `/disable_auto_reply` - Отключить автоответы
- `/reply_to_all` - Отвечать на все сообщения
- `/reply_to_mention` - Отвечать только по упоминанию/команде
- `/set_cooldown значение` - Установить задержку между ответами (в секундах)

### Системная информация:
- `/status` - Показать статус бота и сервисов
- `/help` - Показать список всех команд
