# PersonaForge - Telegram Bot with Human-like AI

## Цель проекта

Создать Telegram-бота на Rust, который ведет диалог "как реальный человек" в личных чатах и в группах/супергруппах, с настраиваемой персоной и памятью на базе RAG (Retrieval Augmented Generation), используя локальную Ollama, запускаемую в Docker без повторной загрузки моделей.

## Реализованный функционал (на текущий момент)

На данный момент реализован базовый каркас бота с ключевыми функциями для демонстрации основной концепции:

-   **Работа в личных чатах:** Бот отвечает на сообщения в личных чатах.
-   **Базовая генерация ответов:** Используется локальная модель Ollama для генерации ответов.
-   **Контекст диалога (short-term memory):** Бот поддерживает контекст последних N сообщений чата (в памяти).
-   **RAG-память:**
    -   Сохранение фактов/фрагментов диалога и/или заметок в локальной базе данных SQLite.
    -   Поиск релевантных фрагментов по embedding similarity (также через Ollama) и добавление их в контекст ответа.
-   **Персона:** Бот использует настраиваемую "манеру речи" через system prompt, который может быть загружен из базы данных.
-   **Docker-first:** Проект настроен для запуска через `docker-compose.yml`, что упрощает развертывание бота и Ollama.
-   **Надёжность:** Встроены базовые механизмы таймаутов на запросы к Ollama и примитивный rate limiting (cooldown) на основе настроек чата.
-   **Безопасность:** Запросы к Ollama обрабатываются с базовой логикой ошибок.
-   **Конфиденциальность:** Хранение данных настроено для локальной SQLite, что обеспечивает контроль над данными.

## Технологии

-   **Язык:** Rust
-   **Telegram SDK:** `teloxide`
-   **LLM:** Ollama (локально)
-   **База данных:** SQLite (через `sqlx`)
-   **Сериализация эмбеддингов:** `bincode`
-   **Асинхронность:** `tokio`
-   **Конфигурация:** `dotenv`, `envy`
-   **Логирование:** `pretty_env_logger`
-   **Контейнеризация:** Docker, `docker-compose`

## Настройка и запуск

Для запуска бота вам потребуется установленный Docker и аккаунт в Telegram для создания бота.

### 1. Клонирование репозитория

```bash
git clone https://github.com/your-username/PersonaForge.git
cd PersonaForge
```

### 2. Создание Telegram-бота

1.  Откройте Telegram и найдите [@BotFather](https://t.me/BotFather).
2.  Отправьте ему команду `/newbot`.
3.  Следуйте инструкциям BotFather, чтобы создать нового бота и получить его токен. Сохраните этот токен.
4.  Получите ваш Telegram User ID, используя бота, например, [@userinfobot](https://t.me/userinfobot). Сохраните этот ID.

### 3. Настройка переменных окружения

Создайте файл `.env` в корневой директории проекта, скопировав `.env.example`:

```bash
cp .env.example .env
```

Затем отредактируйте файл `.env`, заполнив значения:

```ini
TELOXIDE_TOKEN=ВАШ_ТОКЕН_БОТА
DATABASE_URL=sqlite:persona_forge.db
OWNER_ID=ВАШ_TELEGRAM_USER_ID
```

-   `TELOXIDE_TOKEN`: Токен, полученный от BotFather.
-   `DATABASE_URL`: Путь к файлу SQLite базы данных. `sqlite:persona_forge.db` по умолчанию создаст файл `persona_forge.db` в корне проекта.
-   `OWNER_ID`: Ваш Telegram User ID. Это необходимо для будущей панели владельца.

### 4. Подготовка Ollama

Убедитесь, что у вас установлен Docker. Ollama будет запущена как часть `docker-compose`. Модели Ollama будут скачиваться при первом запуске, поэтому это может занять время.

### 5. Запуск бота

Выполните следующую команду в корневой директории проекта:

```bash
docker-compose up --build
```

-   `--build`: Обязателен при первом запуске или после изменений в коде Rust, чтобы пересобрать образ бота.
-   Ollama запустится в отдельном контейнере и начнет скачивать модель по умолчанию (`llama3:latest` и `nomic-embed-text` для эмбеддингов, если они еще не загружены).

После успешного запуска бот будет готов к работе.

### 6. Взаимодействие с ботом

Просто отправляйте сообщения вашему боту в личных сообщениях. Он будет использовать Ollama для генерации ответов, основываясь на текущем контексте и своей RAG-памяти.

## Дальнейшие планы и TODO

Следующие шаги для развития проекта, частично основанные на изначальном ТЗ:

-   **Полная реализация Owner-панели:**
    -   CRUD для персон (создание, редактирование, активация).
    -   Выбор модели Ollama и параметров генерации (temperature, max tokens).
    -   Включение/выключение RAG и настройка глубины памяти.
    -   Просмотр статуса Ollama и БД.
-   **Полная реализация Админки чата:**
    -   Включение/выключение автоответов.
    -   Режим ответа: "только по упоминанию/команде" vs "на все сообщения".
    -   Настройки частоты ответов/антиспам (cooldown).
    -   Контекст (N последних сообщений в prompt).
-   **Улучшение "человечного" поведения:** Добавление правил, чтобы избежать повторений, раскрытия того, что это бот, аккуратное обращение с персональными данными.
-   **Улучшенное логирование и метрики:** Более детальное логирование, трассировка запросов, сбор метрик (время ответа, ошибки Ollama, нагрузка).
-   **Миграции БД:** Автоматическое применение миграций.
-   **Расширение RAG:** Развитие механизма "memory_chunks" для более гранулярного хранения и извлечения информации.
-   **Очереди/лимиты на генерацию:** Дополнительные механизмы для предотвращения перегрузки Ollama.
-   **Обработка ошибок:** БолееRobustная обработка ошибок для запросов к Ollama.

---

**Примечание:** Для корректной работы Ollama вам, возможно, потребуется предварительно выполнить `docker pull ollama/ollama` и `ollama run llama3` (или другую модель, которую вы хотите использовать) вручную, чтобы убедиться, что модели скачаны и доступны. В `docker-compose` бот будет ждать доступности Ollama.
